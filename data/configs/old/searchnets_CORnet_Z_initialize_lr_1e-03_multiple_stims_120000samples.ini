[DATA]
TRAIN_SIZE = 120000
STIM_TYPES = ['RVvGV', 'RVvRHGV', 'PWVvCV', 'PWVvPWHCV', '2_v_5', 'YT_v_BTYL', 'YT_v_BTBL', 'Bx_v_RxBo', 'Bx_v_RxRo', 'TvT']
VALIDATION_SIZE = 1600
TEST_SIZE = 6400
SET_SIZES = [1, 2, 4, 8]
CSV_FILE_IN = ../../visual_search_stimuli/alexnet_multiple_stims/alexnet_multiple_stims.csv
CSV_FILE_OUT = ../../visual_search_stimuli/alexnet_multiple_stims/alexnet_multiple_stims_120000samples_split.csv
TRAIN_SIZE_PER_SET_SIZE = [800, 1600, 3200, 6400]

[TRAIN]
NETNAME = CORnet_Z
EPOCHS = 200
RANDOM_SEED = 42
BATCH_SIZE = 64
SAVE_PATH = ./checkpoints/CORnet_Z_initialize_lr_1e-03_multiple_stims_120000samples

METHOD = initialize
LEARNING_RATE = 0.001

NUMBER_NETS_TO_TRAIN = 8

SAVE_ACC_BY_SET_SIZE_BY_EPOCH = True
USE_VAL = True
VAL_EPOCH = 1
PATIENCE = 3
CHECKPOINT_EPOCH = 2
NUM_WORKERS = 12
DATA_PARALLEL = True

[TEST]
TEST_RESULTS_SAVE_PATH = ./results/CORnet_Z_initialize_lr_1e-03_multiple_stims_120000samples
