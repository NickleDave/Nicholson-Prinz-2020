
@article{wolfeFiveFactorsThat2017,
  title = {Five Factors That Guide Attention in Visual Search},
  volume = {1},
  issn = {23973374},
  doi = {10.1038/s41562-017-0058},
  abstract = {How do we find what we are looking for? Even when the desired target is in the current field of view, we need to search because fundamental limits on visual processing make it impossible to recognize everything at once. Searching involves directing atten- tion to objects that might be the target. This deployment of attention is not random. It is guided to the most promising items and locations by five factors discussed here: bottom-up salience, top-down feature guidance, scene structure and meaning, the pre- vious history of search over timescales ranging from milliseconds to years, and the relative value of the targets and distractors. Modern theories of visual search need to incorporate all five factors and specify how these factors combine to shape search behaviour. An understanding of the rules of guidance can be used to improve the accuracy and efficiency of socially important search tasks, from security screening to medical image perception.},
  number = {3},
  journal = {Nature Human Behaviour},
  author = {Wolfe, Jeremy M. and Horowitz, Todd S.},
  year = {2017},
  pages = {1-8},
  file = {C:\\Users\\Seymour Snyder\\Documents\\Mendeley Desktop\\Wolfe, Horowitz - 2017 - Five factors that guide attention in visual search.pdf},
  pmid = {9384378}
}

@article{khaligh-razaviDeepSupervisedNot2014,
  title = {Deep Supervised, but Not Unsupervised, Models May Explain {{IT}} Cortical Representation},
  volume = {10},
  number = {11},
  journal = {PLoS computational biology},
  author = {{Khaligh-Razavi}, Seyed-Mahdi and Kriegeskorte, Nikolaus},
  year = {2014},
  pages = {e1003915}
}

@article{geislerIdealObserverAnalysis2003,
  title = {Ideal Observer Analysis},
  volume = {10},
  number = {7},
  journal = {The visual neurosciences},
  author = {Geisler, Wilson S.},
  year = {2003},
  pages = {12-12}
}

@article{kriegeskorteDeepNeuralNetworks2015,
  title = {Deep Neural Networks: A New Framework for Modeling Biological Vision and Brain Information Processing},
  volume = {1},
  journal = {Annual review of vision science},
  author = {Kriegeskorte, Nikolaus},
  year = {2015},
  pages = {417-446}
}

@incollection{wolfeVisualSearch1998,
  address = {Hove, England},
  title = {Visual Search},
  isbn = {978-0-86377-812-4 978-0-86377-813-1},
  abstract = {Discusses visual search tasks where the object is visible in the current field of view. The author discusses paradigmatic issues, such as accuracy methods, interpretation of search results, and the description of search performance. The author next describes the properties of preattentive processing, the processing of stimuli that occurs before attention is deployed to an item in a search task. The author then discusses the use of preattentive information by subsequent processes, including stimulus-driven and user-driven processes. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  booktitle = {Attention},
  publisher = {{Psychology Press/Erlbaum (UK) Taylor \& Francis}},
  author = {Wolfe, Jeremy M.},
  year = {1998},
  keywords = {Attention,Cognitive Processes,Visual Search},
  pages = {13-73},
  file = {/home/art/Zotero/storage/B5LQBDSI/1998-07791-001.html}
}

@article{bergenRapidDiscriminationVisual1983,
  title = {Rapid Discrimination of Visual Patterns},
  number = {5},
  journal = {IEEE Transactions on Systems, Man, and Cybernetics},
  author = {Bergen, James R. and Julesz, Bela},
  year = {1983},
  pages = {857-863}
}

@article{geislerModelsOvertAttention2011,
  title = {Models of Overt Attention},
  journal = {Oxford handbook of eye movements},
  author = {Geisler, Wilson S. and Cormack, Lawrence K.},
  year = {2011},
  pages = {439-454}
}

@article{ecksteinVisualSearchRetrospective2011,
  title = {Visual Search: {{A}} Retrospective},
  volume = {11},
  number = {5},
  journal = {Journal of vision},
  author = {Eckstein, Miguel P.},
  year = {2011},
  pages = {14-14}
}

@article{ecksteinLowerVisualSearch1998a,
  title = {The Lower Visual Search Efficiency for Conjunctions Is Due to Noise and Not Serial Attentional Processing},
  volume = {9},
  number = {2},
  journal = {Psychological Science},
  author = {Eckstein, Miguel P.},
  year = {1998},
  pages = {111-118}
}

@article{ecksteinSignalDetectionModel2000,
  title = {A Signal Detection Model Predicts the Effects of Set Size on Visual Search Accuracy for Feature, Conjunction, Triple Conjunction, and Disjunction Displays},
  volume = {62},
  number = {3},
  journal = {Perception \& psychophysics},
  author = {Eckstein, Miguel P. and Thomas, James P. and Palmer, John and Shimozaki, Steven S.},
  year = {2000},
  pages = {425-451}
}

@article{treismanFeatureintegrationTheoryAttention1980,
  title = {A Feature-Integration Theory of Attention},
  volume = {12},
  number = {1},
  journal = {Cognitive psychology},
  author = {Treisman, Anne M. and Gelade, Garry},
  year = {1980},
  pages = {97-136}
}

@article{wolfeGuidedSearchAlternative1989,
  title = {Guided Search: An Alternative to the Feature Integration Model for Visual Search.},
  volume = {15},
  number = {3},
  journal = {Journal of Experimental Psychology: Human perception and performance},
  author = {Wolfe, Jeremy M. and Cave, Kyle R. and Franzel, Susan L.},
  year = {1989},
  pages = {419}
}

@article{wolfeGuidedSearchRevised1994,
  title = {Guided Search 2.0 a Revised Model of Visual Search},
  volume = {1},
  number = {2},
  journal = {Psychonomic bulletin \& review},
  author = {Wolfe, Jeremy M.},
  year = {1994},
  pages = {202-238}
}

@article{palmerSignalDetectionEvidence2011,
  title = {Signal Detection Evidence for Limited Capacity in Visual Search},
  volume = {73},
  number = {8},
  journal = {Attention, Perception, \& Psychophysics},
  author = {Palmer, Evan M. and Fencsik, David E. and Flusberg, Stephen J. and Horowitz, Todd S. and Wolfe, Jeremy M.},
  year = {2011},
  pages = {2413-2424}
}

@article{yaminsUsingGoaldrivenDeep2016,
  title = {Using Goal-Driven Deep Learning Models to Understand Sensory Cortex},
  volume = {19},
  issn = {1546-1726},
  doi = {10.1038/nn.4244},
  abstract = {Fueled by innovation in the computer vision and artificial intelligence communities, recent developments in computational neuroscience have used goal-driven hierarchical convolutional neural networks (HCNNs) to make strides in modeling neural single-unit and population responses in higher visual cortical areas. In this Perspective, we review the recent progress in a broader modeling context and describe some of the key technical innovations that have supported it. We then outline how the goal-driven HCNN approach can be used to delve even more deeply into understanding the development and organization of sensory cortical processing.},
  language = {eng},
  number = {3},
  journal = {Nature Neuroscience},
  author = {Yamins, Daniel L. K. and DiCarlo, James J.},
  month = mar,
  year = {2016},
  keywords = {Animals,Goals,Humans,Learning,Models; Neurological,Neural Networks (Computer),Somatosensory Cortex,Visual Cortex},
  pages = {356-365},
  pmid = {26906502}
}

@article{yaminsPerformanceoptimizedHierarchicalModels2014,
  title = {Performance-Optimized Hierarchical Models Predict Neural Responses in Higher Visual Cortex},
  volume = {111},
  number = {23},
  journal = {Proceedings of the National Academy of Sciences},
  author = {Yamins, Daniel LK and Hong, Ha and Cadieu, Charles F. and Solomon, Ethan A. and Seibert, Darren and DiCarlo, James J.},
  year = {2014},
  pages = {8619--8624},
  file = {/home/art/Zotero/storage/WY2INNG8/Yamins et al. - 2014 - Performance-optimized hierarchical models predict .pdf;/home/art/Zotero/storage/XYGIZ26G/8619.html}
}


