{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lack of evidence for attention-like limits on accuracy of convolutional neural networks performing a visual search task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "What limits our ability to find what we are looking for in the cluttered noisy world? To investigate this, cognitive scientists have long used visual search. In spite of hundreds of studies, it remains unclear how to relate effects found using the discrete item display search task to computations in the visual system. A separate thread of research has studied the visual system of humans and other primates using convolutional neural networks (CNNs) as models. Multiple lines of evidence suggest that training CNNs to perform tasks such as image classification causes them to learn  representations similar to those used by the visual system. These studies raise the question of whether CNNs that have learned such representations behave similarly to humans performing other vision-based tasks. Here we address this by measuring the behavior of CNNs trained for image classification while they perform the discrete item display search task. We first show how a fine-tuning approach often used to adapt pre-trained CNNs to new tasks can produce models that show human-like limitations on this task. However we then demonstrate that we can greatly reduce these effects by changing training,without changing the learned representations. Lastly we show that accuracy is not impaired when single networks are trained to discriminate multiple types of visual search stimuli. Based on these findings, we suggest that CNNs are not necessarily subject to the same limitations as the primate visual system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### The discrete item display search task\n",
    "On each trial, subjects view a display (example images, $\\mathbf{a}$) of discrete items on a flat background. Subjects respond whether the target is present or absent (condition varies across rows of $\\mathbf{a}$). Another condition that varies across trials is the set size, that is, the total number of targets and distractors (varies across rows in $\\mathbf{a}$). Many studies focus on *set size effects*. Typical effects are an increase in reaction time or a decrease in accuracy as set size increases (depicted schematically in $\\mathbf{b}$, redrawn from (Wolfe et al., 2010) and (Eckstein, 1998). Effects vary based on the features that distinguish targets from distractors (shown in columns). Details in introduction. Accuracy for spatial configuration-type stimuli not shown in $\\mathbf{b}$ because this has been less studied (but see E. M. Palmer et al., 2011)\n",
    "\n",
    "![figure 1](../static/fig1/fig1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "### Human-like limits on accuracy of convolutional neural networks (CNNs) performing the discrete item display search task\n",
    "\n",
    "When using weights pre-trained on ImageNet in convolutional layers, and fine-tuning weights in fully-connected layers so AlexNet could perform the task, this CNN showed decreases in accuracy as set size increased ($\\mathbf{a}$). This decrease was smallest for feature search stimuli (left plot), intermediate for conjunction stimuli (middle plot), and largest for spatial configuration stimuli (right plot). The same approach produced similar results with the VGG16 architecture ($\\mathbf{b}$)\n",
    "\n",
    "![Figure 2](../static/fig2/fig2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing training greatly reduces set size effects\n",
    "Training histories showed that the accuracy of models trained with the fine tuning approach did not converge\n",
    "on some asymptotic value, and varied depending on the set size of the search stimuli ($\\textbf{a}$, left plot). Increasing the learning rate and including more examples of stimuli with larger set sizes greatly sped up convergence ($\\textbf{a}$, right plot). AlexNet models trained with this higher learning rate and larger training set showed reduced set size effects ($\\textbf{b}$).\n",
    "![figure 3](../static/fig3/fig3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training single networks on multiple stimuli does not impair accuracy\n",
    "Two instances of AlexNet trained on datasets containing all three types of visual search stimuli used in this study still attained high accuracy.\n",
    "![figure 4](../static/fig4/fig4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "Fine-tuning Alexnet and VGG16:\n",
    "* based on Põder 2017: https://arxiv.org/pdf/1707.09775.pdf\n",
    "* Stochastic gradient descent\n",
    "* Base learning rate: 1e-20\n",
    "* Rate for fully-connected layers: 0.0001\n",
    "* epochs: 200\n",
    "\n",
    "Training  \n",
    "* Freeze convolutional layers\n",
    "* Rate for fully-connected layers: 0.001\n",
    "* Epochs: until validation accuracy did not improve for more than 20 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "## Acknowledgments\n",
    "- Research funded by the Lifelong Learning Machines program, DARPA/Microsystems Technology Office,  DARPA cooperative agreement HR0011-18-2-0019\n",
    "- David Nicholson was partially supported by the 2017 William K. and Katherine W. Estes Fund to F. Pestilli, R. Goldstone and L. Smith, Indiana University Bloomington."
   ]
  }
 ],
 "metadata": {
  "cite2c": {
   "citations": {
    "6027200/6D4LKJD9": {
     "DOI": "10.1016/j.neuron.2018.03.044",
     "URL": "http://www.cell.com/neuron/fulltext/S0896-6273(18)30250-2",
     "abstract": "Summary A core goal of auditory neuroscience is to build quantitative models that predict cortical responses to natural sounds. Reasoning that a complete model of auditory cortex must solve ecologically relevant tasks, we optimized hierarchical neural networks for speech and music recognition. The best-performing network contained separate music and speech pathways following early shared processing, potentially replicating human cortical organization. The network performed both tasks as well as humans and exhibited human-like errors despite not being optimized to do so, suggesting common constraints on network and human performance. The network predicted fMRI voxel responses substantially better than traditional spectrotemporal filter models throughout auditory cortex. It also provided a quantitative signature of cortical representational hierarchy—primary and non-primary responses were best predicted by intermediate and late network layers, respectively. The results suggest that task optimization provides a powerful set of tools for modeling sensory systems.",
     "author": [
      {
       "family": "Kell",
       "given": "Alexander J E"
      },
      {
       "family": "Yamins",
       "given": "Daniel L K"
      },
      {
       "family": "Shook",
       "given": "Erica N"
      },
      {
       "family": "Norman-haignere",
       "given": "Sam V"
      },
      {
       "family": "Mcdermott",
       "given": "Josh H"
      },
      {
       "family": "Kell",
       "given": "Alexander J E"
      },
      {
       "family": "Yamins",
       "given": "Daniel L K"
      },
      {
       "family": "Shook",
       "given": "Erica N"
      },
      {
       "family": "Norman-haignere",
       "given": "Sam V"
      }
     ],
     "container-title": "Neuron",
     "id": "6027200/6D4LKJD9",
     "issued": {
      "year": 2018
     },
     "note": "PMID: 29681533\nPublisher: Elsevier Inc.",
     "page": "1-15",
     "page-first": "1",
     "title": "A Task-Optimized Neural Network Replicates Human Auditory Behavior, Predicts Brain Responses, and Reveals a Cortical Processing Hierarchy",
     "type": "article-journal"
    },
    "6027200/8ISULWGF": {
     "author": [
      {
       "family": "Kriegeskorte",
       "given": "Nikolaus"
      }
     ],
     "container-title": "Annual review of vision science",
     "id": "6027200/8ISULWGF",
     "issued": {
      "year": 2015
     },
     "page": "417-446",
     "page-first": "417",
     "title": "Deep neural networks: a new framework for modeling biological vision and brain information processing",
     "type": "article-journal",
     "volume": "1"
    },
    "6027200/9CAW6DFJ": {
     "author": [
      {
       "family": "Poder",
       "given": "Endel"
      }
     ],
     "container-title": "arXiv preprint arXiv:1707.09775",
     "id": "6027200/9CAW6DFJ",
     "issued": {
      "year": 2017
     },
     "title": "Capacity limitations of visual search in deep convolutional neural network",
     "type": "article-journal"
    },
    "6027200/AEJJ5749": {
     "ISBN": "978-0-86377-812-4 978-0-86377-813-1",
     "abstract": "Discusses visual search tasks where the object is visible in the current field of view. The author discusses paradigmatic issues, such as accuracy methods, interpretation of search results, and the description of search performance. The author next describes the properties of preattentive processing, the processing of stimuli that occurs before attention is deployed to an item in a search task. The author then discusses the use of preattentive information by subsequent processes, including stimulus-driven and user-driven processes. (PsycINFO Database Record (c) 2016 APA, all rights reserved)",
     "author": [
      {
       "family": "Wolfe",
       "given": "Jeremy M."
      }
     ],
     "container-title": "Attention",
     "event-place": "Hove, England",
     "id": "6027200/AEJJ5749",
     "issued": {
      "year": 1998
     },
     "page": "13-73",
     "page-first": "13",
     "publisher": "Psychology Press/Erlbaum (UK) Taylor & Francis",
     "publisher-place": "Hove, England",
     "title": "Visual search",
     "type": "chapter"
    },
    "6027200/B49GIRUD": {
     "ISBN": "0-19-852479-X",
     "author": [
      {
       "family": "Findlay",
       "given": "John M."
      },
      {
       "family": "Gilchrist",
       "given": "Iain D."
      }
     ],
     "id": "6027200/B49GIRUD",
     "issued": {
      "year": 2003
     },
     "publisher": "Oxford University Press",
     "title": "Active vision: The psychology of looking and seeing",
     "type": "book"
    },
    "6027200/EQTU2P3Z": {
     "author": [
      {
       "family": "Bobadilla-Suarez",
       "given": "Sebastian"
      },
      {
       "family": "Ahlheim",
       "given": "Christiane"
      },
      {
       "family": "Mehrotra",
       "given": "Abhinav"
      },
      {
       "family": "Panos",
       "given": "Aristeidis"
      },
      {
       "family": "Love",
       "given": "Bradley C."
      }
     ],
     "container-title": "BioRxiv",
     "id": "6027200/EQTU2P3Z",
     "issued": {
      "year": 2018
     },
     "page": "439893",
     "page-first": "439893",
     "title": "Measures of neural similarity",
     "type": "article-journal"
    },
    "6027200/EXC2Q22Y": {
     "id": "6027200/EXC2Q22Y",
     "title": "Diedrichsen, Kriegeskorte - 2017 - Representational models A common framework for understanding encoding, pattern-component, and represe.pdf",
     "type": "article"
    },
    "6027200/IQ2Y895S": {
     "author": [
      {
       "family": "Diedrichsen",
       "given": "Jörn"
      },
      {
       "family": "Kriegeskorte",
       "given": "Nikolaus"
      }
     ],
     "container-title": "PLoS computational biology",
     "id": "6027200/IQ2Y895S",
     "issue": "4",
     "issued": {
      "year": 2017
     },
     "page": "e1005508",
     "page-first": "e1005508",
     "title": "Representational models: A common framework for understanding encoding, pattern-component, and representational-similarity analysis",
     "type": "article-journal",
     "volume": "13"
    },
    "6027200/KEUFZ7BF": {
     "author": [
      {
       "family": "Lake",
       "given": "Brenden M."
      },
      {
       "family": "Ullman",
       "given": "Tomer D."
      },
      {
       "family": "Tenenbaum",
       "given": "Joshua B."
      },
      {
       "family": "Gershman",
       "given": "Samuel J."
      }
     ],
     "container-title": "Behavioral and Brain Sciences",
     "id": "6027200/KEUFZ7BF",
     "issued": {
      "year": 2017
     },
     "title": "Building machines that learn and think like people",
     "type": "article-journal",
     "volume": "40"
    },
    "6027200/KYF4NSZP": {
     "DOI": "10.1016/0010-0285(80)90005-5",
     "author": [
      {
       "family": "Treisman",
       "given": "Anne M"
      },
      {
       "family": "Gelade",
       "given": "Garry"
      }
     ],
     "container-title": "Cognitive Psychology",
     "id": "6027200/KYF4NSZP",
     "issue": "1",
     "issued": {
      "year": 1980
     },
     "note": "PMID: 7351125\narXiv: cs/9605103\nISBN: 0010-0285",
     "page": "97-136",
     "page-first": "97",
     "title": "A feature-integration of attention",
     "type": "article-journal",
     "volume": "12"
    },
    "6027200/LHVT6V6M": {
     "author": [
      {
       "family": "Banino",
       "given": "Andrea"
      },
      {
       "family": "Barry",
       "given": "Caswell"
      },
      {
       "family": "Uria",
       "given": "Benigno"
      },
      {
       "family": "Blundell",
       "given": "Charles"
      },
      {
       "family": "Lillicrap",
       "given": "Timothy"
      },
      {
       "family": "Mirowski",
       "given": "Piotr"
      },
      {
       "family": "Pritzel",
       "given": "Alexander"
      },
      {
       "family": "Chadwick",
       "given": "Martin J."
      },
      {
       "family": "Degris",
       "given": "Thomas"
      },
      {
       "family": "Modayil",
       "given": "Joseph"
      }
     ],
     "container-title": "Nature",
     "id": "6027200/LHVT6V6M",
     "issue": "7705",
     "issued": {
      "year": 2018
     },
     "page": "429",
     "page-first": "429",
     "title": "Vector-based navigation using grid-like representations in artificial agents",
     "type": "article-journal",
     "volume": "557"
    },
    "6027200/LJEPEDWB": {
     "author": [
      {
       "family": "Wolfe",
       "given": "Jeremy M"
      }
     ],
     "id": "6027200/LJEPEDWB",
     "issue": "1",
     "issued": {
      "year": 2016
     },
     "page": "33-39",
     "page-first": "33",
     "title": "What Can 1 Million Trials Tell Us about Visual Search ? Author ( s ): Jeremy M . Wolfe Published by : Sage Publications , Inc . on behalf of the Association for Psychological Science Stable URL : http://www.jstor.org/stable/40063243 Accessed : 08-07-2016",
     "type": "article-journal",
     "volume": "9"
    },
    "6027200/PAZZI897": {
     "author": [
      {
       "family": "Marcus",
       "given": "Gary"
      }
     ],
     "container-title": "arXiv preprint arXiv:1801.00631",
     "id": "6027200/PAZZI897",
     "issued": {
      "year": 2018
     },
     "title": "Deep learning: A critical appraisal",
     "type": "article-journal"
    },
    "6027200/QCQFYFDZ": {
     "author": [
      {
       "family": "Wolfe",
       "given": "Jeremy M."
      },
      {
       "family": "Palmer",
       "given": "Evan M."
      },
      {
       "family": "Horowitz",
       "given": "Todd S."
      }
     ],
     "container-title": "Vision research",
     "id": "6027200/QCQFYFDZ",
     "issue": "14",
     "issued": {
      "year": 2010
     },
     "page": "1304-1311",
     "page-first": "1304",
     "title": "Reaction time distributions constrain models of visual search",
     "type": "article-journal",
     "volume": "50"
    },
    "6027200/SAZAIFBG": {
     "author": [
      {
       "family": "Cueva",
       "given": "Christopher J."
      },
      {
       "family": "Wei",
       "given": "Xue-Xin"
      }
     ],
     "container-title": "arXiv preprint arXiv:1803.07770",
     "id": "6027200/SAZAIFBG",
     "issued": {
      "year": 2018
     },
     "title": "Emergence of grid-like representations by training recurrent neural networks to perform spatial localization",
     "type": "article-journal"
    },
    "6027200/U77Y74SI": {
     "author": [
      {
       "family": "Khaligh-Razavi",
       "given": "Seyed-Mahdi"
      },
      {
       "family": "Kriegeskorte",
       "given": "Nikolaus"
      }
     ],
     "container-title": "PLoS computational biology",
     "id": "6027200/U77Y74SI",
     "issue": "11",
     "issued": {
      "year": 2014
     },
     "page": "e1003915",
     "page-first": "e1003915",
     "title": "Deep supervised, but not unsupervised, models may explain IT cortical representation",
     "type": "article-journal",
     "volume": "10"
    },
    "6027200/WGZWMWX7": {
     "author": [
      {
       "family": "Krizhevsky",
       "given": "Alex"
      },
      {
       "family": "Sutskever",
       "given": "Ilya"
      },
      {
       "family": "Hinton",
       "given": "Geoffrey E."
      }
     ],
     "container-title": "Advances in neural information processing systems",
     "id": "6027200/WGZWMWX7",
     "issued": {
      "year": 2012
     },
     "page": "1097-1105",
     "page-first": "1097",
     "title": "Imagenet classification with deep convolutional neural networks",
     "type": "paper-conference"
    },
    "6027200/ZT5GRNIN": {
     "author": [
      {
       "family": "Cadieu",
       "given": "Charles F."
      },
      {
       "family": "Hong",
       "given": "Ha"
      },
      {
       "family": "Yamins",
       "given": "Dan"
      },
      {
       "family": "Pinto",
       "given": "Nicolas"
      },
      {
       "family": "Majaj",
       "given": "Najib J."
      },
      {
       "family": "DiCarlo",
       "given": "James J."
      }
     ],
     "container-title": "arXiv preprint arXiv:1301.3530",
     "id": "6027200/ZT5GRNIN",
     "issued": {
      "year": 2013
     },
     "title": "The neural representation benchmark and its evaluation on brain and machine",
     "type": "article-journal"
    }
   }
  },
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
