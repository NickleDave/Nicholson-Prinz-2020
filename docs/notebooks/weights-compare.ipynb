{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hdf5(path):\n",
    "    \"\"\"only works for VGG16 that has Keras formatting of hdf5 file\"\"\"\n",
    "    weights = {}\n",
    "\n",
    "    keys = []\n",
    "    with h5py.File(path, 'r') as f: # open file\n",
    "        f.visit(keys.append) # append all keys to list\n",
    "        for key in keys:\n",
    "            if ':' in key: # contains data if ':' in key\n",
    "                weights[f[key].name] = f[key].value\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bart/Documents/repos/L2M/visual-search-nets/data/neural_net_weights/VGG16_weights\n"
     ]
    }
   ],
   "source": [
    "cd /home/bart/Documents/repos/L2M/visual-search-nets/data/neural_net_weights/VGG16_weights/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bart/anaconda3/envs/sntf2p0/lib/python3.6/site-packages/h5py/_hl/dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "vgg16_weights_hdf5 = read_hdf5('vgg16_weights_tf_dim_ordering_tf_kernels.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bart/Documents/repos/L2M/visual-search-nets/data/neural_net_weights\n"
     ]
    }
   ],
   "source": [
    "cd /home/bart/Documents/repos/L2M/visual-search-nets/data/neural_net_weights/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_weights_npz = np.load('vgg16_weights.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv1_1_W',\n",
       " 'conv1_1_b',\n",
       " 'conv1_2_W',\n",
       " 'conv1_2_b',\n",
       " 'conv2_1_W',\n",
       " 'conv2_1_b',\n",
       " 'conv2_2_W',\n",
       " 'conv2_2_b',\n",
       " 'conv3_1_W',\n",
       " 'conv3_1_b',\n",
       " 'conv3_2_W',\n",
       " 'conv3_2_b',\n",
       " 'conv3_3_W',\n",
       " 'conv3_3_b',\n",
       " 'conv4_1_W',\n",
       " 'conv4_1_b',\n",
       " 'conv4_2_W',\n",
       " 'conv4_2_b',\n",
       " 'conv4_3_W',\n",
       " 'conv4_3_b',\n",
       " 'conv5_1_W',\n",
       " 'conv5_1_b',\n",
       " 'conv5_2_W',\n",
       " 'conv5_2_b',\n",
       " 'conv5_3_W',\n",
       " 'conv5_3_b',\n",
       " 'fc6_W',\n",
       " 'fc6_b',\n",
       " 'fc7_W',\n",
       " 'fc7_b',\n",
       " 'fc8_W',\n",
       " 'fc8_b']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(vgg16_weights_npz.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_convert = {'/block1_conv1/block1_conv1_W_1:0': 'conv1_1_W',\n",
    "                 '/block1_conv1/block1_conv1_b_1:0': 'conv1_1_b',\n",
    "                 '/block1_conv2/block1_conv2_W_1:0': 'conv1_2_W',\n",
    "                 '/block1_conv2/block1_conv2_b_1:0': 'conv1_2_b',\n",
    "                 '/block2_conv1/block2_conv1_W_1:0': 'conv2_1_W',\n",
    "                 '/block2_conv1/block2_conv1_b_1:0': 'conv2_1_b',\n",
    "                 '/block2_conv2/block2_conv2_W_1:0': 'conv2_2_W',\n",
    "                 '/block2_conv2/block2_conv2_b_1:0': 'conv2_2_b',\n",
    "                 '/block3_conv1/block3_conv1_W_1:0': 'conv3_1_W',\n",
    "                 '/block3_conv1/block3_conv1_b_1:0': 'conv3_1_b',\n",
    "                 '/block3_conv2/block3_conv2_W_1:0': 'conv3_2_W',\n",
    "                 '/block3_conv2/block3_conv2_b_1:0': 'conv3_2_b',\n",
    "                 '/block3_conv3/block3_conv3_W_1:0': 'conv3_3_W',\n",
    "                 '/block3_conv3/block3_conv3_b_1:0': 'conv3_3_b',\n",
    "                 '/block4_conv1/block4_conv1_W_1:0': 'conv4_1_W',\n",
    "                 '/block4_conv1/block4_conv1_b_1:0': 'conv4_1_b',\n",
    "                 '/block4_conv2/block4_conv2_W_1:0': 'conv4_2_W',\n",
    "                 '/block4_conv2/block4_conv2_b_1:0': 'conv4_2_b',\n",
    "                 '/block4_conv3/block4_conv3_W_1:0': 'conv4_3_W',\n",
    "                 '/block4_conv3/block4_conv3_b_1:0': 'conv4_3_b',\n",
    "                 '/block5_conv1/block5_conv1_W_1:0': 'conv5_1_W',\n",
    "                 '/block5_conv1/block5_conv1_b_1:0': 'conv5_1_b',\n",
    "                 '/block5_conv2/block5_conv2_W_1:0': 'conv5_2_W',\n",
    "                 '/block5_conv2/block5_conv2_b_1:0': 'conv5_2_b',\n",
    "                 '/block5_conv3/block5_conv3_W_1:0': 'conv5_3_W',\n",
    "                 '/block5_conv3/block5_conv3_b_1:0': 'conv5_3_b',\n",
    "                 '/fc1/fc1_W_1:0': 'fc6_W',\n",
    "                 '/fc1/fc1_b_1:0': 'fc6_b',\n",
    "                 '/fc2/fc2_W_1:0': 'fc7_W',\n",
    "                 '/fc2/fc2_b_1:0': 'fc7_b',\n",
    "                 '/predictions/predictions_W_1:0': 'fc8_W',\n",
    "                 '/predictions/predictions_b_1:0': 'fc8_b'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vgg16_weights_dict = {}\n",
    "for k_c, v_c in keys_convert.items():\n",
    "    new_vgg16_weights_dict[v_c] = vgg16_weights_hdf5[k_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save weights from Keras as .npy files so we can feed as arrays into `load_weights` and not have to think about Keras .hdf5 file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYERS_WITH_LOADABLE_WEIGHTS = ['conv1_1',\n",
    "                                'conv1_2',\n",
    "                                'conv2_1',\n",
    "                                'conv2_2',\n",
    "                                'conv3_1',\n",
    "                                'conv3_2',\n",
    "                                'conv3_3',\n",
    "                                'conv4_1',\n",
    "                                'conv4_2',\n",
    "                                'conv4_3',\n",
    "                                'conv5_1',\n",
    "                                'conv5_2',\n",
    "                                'conv5_3',\n",
    "                                'fc6',\n",
    "                                'fc7',\n",
    "                                'fc8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bart/Documents/repos/L2M/visual-search-nets/data/neural_net_weights/VGG16_weights\n"
     ]
    }
   ],
   "source": [
    "cd VGG16_weights/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in LAYERS_WITH_LOADABLE_WEIGHTS:\n",
    "        w = new_vgg16_weights_dict[f'{layer}_W']\n",
    "        b = new_vgg16_weights_dict[f'{layer}_b']\n",
    "        np.save(f'{layer}_weights.npy', w)\n",
    "        b = np.save(f'{layer}_biases.npy', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_1_W_hdf5 = vgg16_weights_hdf5['/block1_conv1/block1_conv1_W_1:0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3, 64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1_1_W_npz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3, 64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1_1_W_hdf5.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# first layer from has weights flipped to avoid doing RGB -> BGR\n",
    "(this is very confusing if you don't know that it's the case)  \n",
    "using .npz weights from <https://www.cs.toronto.edu/~frossard/post/vgg16/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.4800154 ,  0.55037946,  0.42947057],\n",
       "        [ 0.4085474 ,  0.44007453,  0.373467  ],\n",
       "        [-0.06514555, -0.08138704, -0.06136011]],\n",
       "\n",
       "       [[ 0.31047726,  0.34573907,  0.27476987],\n",
       "        [ 0.05020237,  0.04063221,  0.03868078],\n",
       "        [-0.40338343, -0.4535013 , -0.36722335]],\n",
       "\n",
       "       [[-0.05087169, -0.05863491, -0.05746817],\n",
       "        [-0.2852275 , -0.33066967, -0.26224968],\n",
       "        [-0.41851634, -0.4850302 , -0.35009676]]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1_1_W_npz[:, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.42947057,  0.55037946,  0.4800154 ],\n",
       "        [ 0.373467  ,  0.44007453,  0.4085474 ],\n",
       "        [-0.06136011, -0.08138704, -0.06514555]],\n",
       "\n",
       "       [[ 0.27476987,  0.34573907,  0.31047726],\n",
       "        [ 0.03868078,  0.04063221,  0.05020237],\n",
       "        [-0.36722335, -0.4535013 , -0.40338343]],\n",
       "\n",
       "       [[-0.05746817, -0.05863491, -0.05087169],\n",
       "        [-0.26224968, -0.33066967, -0.2852275 ],\n",
       "        [-0.35009676, -0.4850302 , -0.41851634]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1_1_W_hdf5[:, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bart/Documents/repos/L2M/visual-search-nets/data/neural_net_weights\n"
     ]
    }
   ],
   "source": [
    "cd /home/bart/Documents/repos/L2M/visual-search-nets/data/neural_net_weights/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34malexnet_weights\u001b[0m/  bvlc_alexnet.npy  \u001b[01;34mVGG16_weights\u001b[0m/  vgg16_weights.npz\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bvlc_alexnet.npy', \"rb\") as weights_fp:\n",
    "    # use item to get dictionary saved in a numpy array\n",
    "    alexnet_weights_npy = np.load(weights_fp, encoding=\"latin1\").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9216, 4096)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet_weights_npy['fc6'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc6_list = np.split(alexnet_weights_npy['fc6'][0], 2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10816.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13 * 13 * 128 / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9216, 2048)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc6_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bart/Documents/repos/L2M/visual-search-nets/data/neural_net_weights/alexnet_weights\n"
     ]
    }
   ],
   "source": [
    "cd alexnet_weights/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alexnet_weights.h5      conv4_1_biases.npy   fc6_biases.npy\n",
      "\u001b[0m\u001b[01;31malexnet_weights.tar.gz\u001b[0m  conv4_1_weights.npy  fc6_weights.npy\n",
      "conv1_biases.npy        conv4_2_biases.npy   fc7_0_biases.npy\n",
      "conv1_weights.npy       conv4_2_weights.npy  fc7_0_weights.npy\n",
      "conv2_1_biases.npy      conv5_1_biases.npy   fc7_1_biases.npy\n",
      "conv2_1_weights.npy     conv5_1_weights.npy  fc7_1_weights.npy\n",
      "conv2_2_biases.npy      conv5_2_biases.npy   fc7_biases.npy\n",
      "conv2_2_weights.npy     conv5_2_weights.npy  fc7_weights.npy\n",
      "conv3_1_biases.npy      fc6_0_biases.npy     fc8_biases.npy\n",
      "conv3_1_weights.npy     fc6_0_weights.npy    fc8_weights.npy\n",
      "conv3_2_biases.npy      fc6_1_biases.npy\n",
      "conv3_2_weights.npy     fc6_1_weights.npy\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_split = ['fc6', 'fc7']\n",
    "for split in to_split:\n",
    "    w_split= np.split(alexnet_weights_npy[split][0], 2, axis=1)\n",
    "    b_split= np.split(alexnet_weights_npy[split][1], 2)\n",
    "    for ind, (w, b) in enumerate(zip(w_split, b_split)):\n",
    "        np.save(f'{split}_{ind + 1}_weights', w)\n",
    "        np.save(f'{split}_{ind + 1}_biases', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import searchnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = searchnets.nets.alexnet.build(n_classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bart/Documents/repos/L2M/visual-search-nets/src/searchnets/nets/alexnet_weights\n"
     ]
    }
   ],
   "source": [
    "cd /home/bart/Documents/repos/L2M/visual-search-nets/src/searchnets/nets/alexnet_weights/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet_weights_hdf5 = {}\n",
    "alexnet_h5 = h5py.File('alexnet_weights.h5', 'r')\n",
    "for key, value in alexnet_h5.items():\n",
    "    if 'conv' in key:\n",
    "        if len(value) == 2:\n",
    "            w_b_dict = {}\n",
    "            w_b_dict['weights'] = value[f'{key}_W']\n",
    "            w_b_dict['biases'] = value[f'{key}_b']\n",
    "        alexnet_weights_hdf5[key] = w_b_dict\n",
    "    elif 'dense' in key:\n",
    "        alexnet_weights_hdf5[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['conv_1', 'conv_2', 'conv_2_1', 'conv_2_2', 'conv_3', 'conv_4', 'conv_4_1', 'conv_4_2', 'conv_5', 'conv_5_1', 'conv_5_2', 'convpool_1', 'convpool_5'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet_weights_hdf5.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet_conv4_1_W_hdf5 = alexnet_weights_hdf5['conv_4_1']['weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 192, 3, 3)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet_conv4_1_W_hdf5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 192, 384)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet_conv4_W_npy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet_layers_dict = {\n",
    "    'conv1': {'group': 1},\n",
    "    'conv2': {'group': 2},\n",
    "    'conv3': {'group': 1},\n",
    "    'conv4': {'group': 2},\n",
    "    'conv5': {'group': 2},\n",
    "    'fc6': {'group': 1},\n",
    "    'fc7': {'group': 1},\n",
    "    'fc8': {'group': 1},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fc6', 'fc7', 'fc8', 'conv3', 'conv2', 'conv1', 'conv5', 'conv4']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(alexnet_weights_npy.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet_weights_npy['conv2'][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_alexnet_weights_dict = {}\n",
    "for layer, group_dict in alexnet_layers_dict.items():\n",
    "    w = alexnet_weights_npy[layer][0]\n",
    "    b = alexnet_weights_npy[layer][1]\n",
    "    if group_dict['group'] > 1:\n",
    "        w_split = np.split(w, group_dict['group'], axis=3)\n",
    "        b_split = np.split(b, group_dict['group'])\n",
    "        for ind, (w, b) in enumerate(zip(w_split, b_split)):\n",
    "            new_alexnet_weights_dict[f'{layer}_{ind}_W'] = \n",
    "    else:\n",
    "        new_alexnet_weights_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
