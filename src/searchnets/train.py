import numpy as np
import torch

from .classes.transfer_trainer import TransferTrainer
from .classes.trainer import Trainer
from .utils.general import make_save_path


def train(csv_file,
          net_name,
          number_nets_to_train,
          epochs_list,
          batch_size,
          random_seed,
          save_path,
          method='transfer',
          num_classes=2,
          learning_rate=None,
          base_learning_rate=1e-20,
          new_learn_rate_layers='fc8',
          new_layer_learning_rate=0.001,
          freeze_trained_weights=True,
          loss_func='CE',
          optimizer='SGD',
          use_val=True,
          val_epoch=1,
          summary_step=None,
          patience=None,
          checkpoint_epoch=10,
          save_acc_by_set_size_by_epoch=False,
          num_workers=4,
          data_parallel=False):
    """train neural networks to perform visual search task.

    Parameters
    ----------
    csv_file : str
        name of .csv file containing prepared data sets.
        Generated by searchnets.data.split function from a csv created by the searchstims library.
    net_name : str
        name of convolutional neural net architecture to train.
        One of {'alexnet', 'VGG16'}
    number_nets_to_train : int
        number of training "replicates"
    epochs_list : list
        of training epochs. Replicates will be trained for each
        value in this list. Can also just be one value, but a list
        is useful if you want to test whether effects depend on
        number of training epochs.
    batch_size : int
        number of samples in a batch of training data
    random_seed : int
        to seed random number generator
    save_path : str
        path to directory where checkpoints and train models were saved
    method : str
        training method. One of {'initialize', 'transfer'}.
        'initialize' means randomly initialize all weights and train the
        networks "from scratch".
        'transfer' means perform transfer learning, using weights pre-trained
        on imagenet.
        Default is 'transfer'.

    Other Parameters
    ----------------
    num_classes : int
        number of classes. Default is 2 (target present, target absent).
    base_learning_rate : float
        Applied to layers with weights loaded from training the
        architecture on ImageNet. Should be a very small number
        so the trained weights don't change much.
    freeze_trained_weights : bool
        if True, freeze weights in any layer not in "new_learn_rate_layers".
        These are the layers that have weights pre-trained on ImageNet.
        Default is False. Done by simply not applying gradients to these weights,
        i.e. this will ignore a base_learning_rate if you set it to something besides zero.
    new_learn_rate_layers : list
        of layer names whose weights will be initialized randomly
        and then trained with the 'new_layer_learning_rate'.
    new_layer_learning_rate : float
        Applied to `new_learn_rate_layers'. Should be larger than
        `base_learning_rate` but still smaller than the usual
        learning rate for a deep net trained with SGD,
        e.g. 0.001 instead of 0.01
    loss_func : str
        type of loss function to use. One of {'CE', 'InvDPrime', 'triplet'}. Default is 'CE',
        the standard cross-entropy loss. 'InvDPrime' is inverse D prime. 'triplet' is triplet loss
        used in face recognition and biometric applications.
    optimizer : str
        optimizer to use. One of {'SGD', 'Adam', 'AdamW'}.
    triplet_loss_margin : float
        Minimum margin between clusters, parameter in triplet loss function. Default is 0.5.
    squared_dist : bool
        if True, when computing similarity of embeddings (e.g. for triplet loss), use pairwise squared
        distance, i.e. Euclidean distance.
    save_acc_by_set_size_by_epoch : bool
        if True, compute accuracy on training set for each epoch separately
        for each unique set size in the visual search stimuli. These values
        are saved in a matrix where rows are epochs and columns are set sizes.
        Useful for seeing whether accuracy converges for each individual
        set size. Default is False.
    use_val : bool
        if True, use validation set.
    val_epoch : int
        if not None, accuracy on validation set will be measured every `val_epoch` epochs. Default is None.
    summary_step : int
        Step on which to write summaries to file. Each minibatch is counted as one step, and steps are counted across
        epochs. Default is None.
    patience : int
        if not None, training will stop if accuracy on validation set has not improved in `patience` steps
    num_workers : int
        number of workers used by torch.DataLoaders. Default is 4.
    data_parallel : bool
        if True, use torch.nn.dataparallel to train network on multiple GPUs. Default is False.

    Returns
    -------
    None
    """
    if use_val and val_epoch is None or val_epoch < 1 or type(val_epoch) != int:
        raise ValueError(
            f'invalid value for val_epoch: {val_epoch}. Validation epoch must be positive integer'
        )

    if use_val is False and patience is not None:
        raise ValueError('patience argument only works with a validation set')

    if patience is not None:
        if type(val_epoch) != int or patience < 1:
            raise TypeError('patience must be a positive integer')

    if type(epochs_list) is int:
        epochs_list = [epochs_list]
    elif type(epochs_list) is list:
        pass
    else:
        raise TypeError("'EPOCHS' option in 'TRAIN' section of config.ini file parsed "
                        f"as invalid type: {type(epochs_list)}")

    if random_seed:
        np.random.seed(random_seed)  # for shuffling in batch_generator
        torch.manual_seed(random_seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False

    if torch.cuda.is_available():
        device = torch.device('cuda')
    else:
        device = torch.device('cpu')

    for epochs in epochs_list:
        print(f'training {net_name} model for {epochs} epochs')
        for net_number in range(1, number_nets_to_train + 1):
            save_path_this_net = make_save_path(save_path, net_name, net_number, epochs)
            if method == 'transfer':
                trainer = TransferTrainer.from_config(net_name=net_name,
                                                      new_learn_rate_layers=new_learn_rate_layers,
                                                      freeze_trained_weights=freeze_trained_weights,
                                                      base_learning_rate=base_learning_rate,
                                                      new_layer_learning_rate=new_layer_learning_rate,
                                                      csv_file=csv_file,
                                                      save_path=save_path_this_net,
                                                      num_classes=num_classes,
                                                      loss_func=loss_func,
                                                      optimizer=optimizer,
                                                      save_acc_by_set_size_by_epoch=save_acc_by_set_size_by_epoch,
                                                      batch_size=batch_size,
                                                      epochs=epochs,
                                                      val_epoch=val_epoch,
                                                      use_val=use_val,
                                                      patience=patience,
                                                      checkpoint_epoch=checkpoint_epoch,
                                                      summary_step=summary_step,
                                                      device=device,
                                                      num_workers=num_workers,
                                                      data_parallel=data_parallel)
            elif method == 'initialize':
                trainer = Trainer.from_config(net_name=net_name,
                                              csv_file=csv_file,
                                              save_path=save_path_this_net,
                                              num_classes=num_classes,
                                              loss_func=loss_func,
                                              optimizer=optimizer,
                                              learning_rate=learning_rate,
                                              save_acc_by_set_size_by_epoch=save_acc_by_set_size_by_epoch,
                                              batch_size=batch_size,
                                              epochs=epochs,
                                              val_epoch=val_epoch,
                                              use_val=use_val,
                                              patience=patience,
                                              checkpoint_epoch=checkpoint_epoch,
                                              summary_step=summary_step,
                                              device=device,
                                              num_workers=num_workers,
                                              data_parallel=data_parallel)

            trainer.train()
